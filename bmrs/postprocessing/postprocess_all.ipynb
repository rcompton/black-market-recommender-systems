{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dateutil\n",
    "import os\n",
    "import ast\n",
    "\n",
    "import logging\n",
    "FORMAT = '%(asctime)-15s %(levelname)-6s %(message)s'\n",
    "DATE_FORMAT = '%b %d %H:%M:%S'\n",
    "formatter = logging.Formatter(fmt=FORMAT, datefmt=DATE_FORMAT)\n",
    "handler = logging.StreamHandler()\n",
    "handler.setFormatter(formatter)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.addHandler(handler)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "META_CATS = ['Other','Drugs','Services', 'Custom Listings', 'DRUGS & MORE',\n",
    "             'other service','other drugs','others', 'digital', 'drug']\n",
    "META_CATS = [s.lower() for s in META_CATS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_agora():\n",
    "    DATA_DIR='/home/aahu/Dropbox/black-market-recommender-systems/data/agora/'\n",
    "    l=[]\n",
    "    for fname in os.listdir(DATA_DIR):\n",
    "        if fname.endswith('.tsv'):\n",
    "            df0 = pd.read_csv(os.path.join(DATA_DIR,fname), sep='\\t', parse_dates=['scrape_date'])\n",
    "            l.append(df0)\n",
    "    df = pd.concat(l)\n",
    "    logger.info(df.columns)\n",
    "    logger.info(df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_pandora():\n",
    "    DATA_DIR='/home/aahu/Dropbox/black-market-recommender-systems/data/pandora/'\n",
    "    l=[]\n",
    "    for fname in os.listdir(DATA_DIR):\n",
    "        if fname.endswith('.tsv'):\n",
    "            try:\n",
    "                df0 = pd.read_csv(os.path.join(DATA_DIR,fname), sep='\\t', parse_dates=['scrape_date'])\n",
    "                l.append(df0)\n",
    "            except ValueError:\n",
    "                #logger.exception('no data')\n",
    "                pass\n",
    "    df = pd.concat(l)\n",
    "    logger.info(df.columns)\n",
    "    logger.info(df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_cloudnine():\n",
    "    DATA_DIR='/home/aahu/Dropbox/black-market-recommender-systems/data/cloudnine/'\n",
    "    l=[]\n",
    "    for fname in os.listdir(DATA_DIR):\n",
    "        if fname.endswith('.tsv'):\n",
    "            try:\n",
    "                df0 = pd.read_csv(os.path.join(DATA_DIR,fname), sep='\\t', parse_dates=['scrape_date'])\n",
    "                l.append(df0)\n",
    "            except ValueError:\n",
    "                logger.exception('no data')\n",
    "                pass\n",
    "    df = pd.concat(l)\n",
    "    logger.info(df.columns)\n",
    "    logger.info(df.shape)\n",
    "    \n",
    "    #be consistent\n",
    "    df.rename(columns={'scraped_date':'scrape_date'}, inplace=True)\n",
    "    df['cat'] = df['cat'].map(lambda x: ast.literal_eval(x))\n",
    "    df['category'] = df['cat'].map(lambda x: x[-1])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_hydra():\n",
    "    DATA_DIR='/home/aahu/Dropbox/black-market-recommender-systems/data/hydra/'\n",
    "    l=[]\n",
    "    for fname in os.listdir(DATA_DIR):\n",
    "        if fname.endswith('.tsv'):\n",
    "            try:\n",
    "                df0 = pd.read_csv(os.path.join(DATA_DIR,fname), sep='\\t', parse_dates=['scrape_date'])\n",
    "                l.append(df0)\n",
    "            except ValueError:\n",
    "                logger.exception('no data')\n",
    "                pass\n",
    "    df = pd.concat(l)\n",
    "    logger.info(df.columns)\n",
    "    logger.info(df.shape)\n",
    "    \n",
    "    #be consistent\n",
    "    df.rename(columns={'scraped_date':'scrape_date'}, inplace=True)\n",
    "    df['cat'] = df['category'].map(lambda x: ast.literal_eval(x))\n",
    "    df['category'] = df['cat'].map(lambda x: x[-1])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_evolution():\n",
    "    DATA_DIR='/home/aahu/Dropbox/black-market-recommender-systems/data/evolution/'\n",
    "    l=[]\n",
    "    for fname in os.listdir(DATA_DIR):\n",
    "        if fname.endswith('.tsv'):\n",
    "            try:\n",
    "                df0 = pd.read_csv(os.path.join(DATA_DIR,fname), sep='\\t', parse_dates=['scrape_date'])\n",
    "                l.append(df0)\n",
    "            except ValueError:\n",
    "                logger.exception('no data')\n",
    "                pass\n",
    "    df = pd.concat(l)\n",
    "    logger.info(df.columns)\n",
    "    logger.info(df.shape)\n",
    "    \n",
    "    #be consistent\n",
    "    #df.rename(columns={'scraped_date':'scrape_date'}, inplace=True)\n",
    "    #df['cat'] = df['category'].map(lambda x: ast.literal_eval(x))\n",
    "    #df['category'] = df['cat'].map(lambda x: x[-1])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def postprocess(df):\n",
    "    \"\"\"\n",
    "    standardized postprocessing\n",
    "    \"\"\"\n",
    "    #normalize\n",
    "    df['category'] = df['category'].map(lambda x:x.lower())\n",
    "    \n",
    "    #discard meta-categories\n",
    "    df = df[df['category'].map(lambda x:x not in META_CATS)]\n",
    "    logger.info(df.shape)\n",
    "    \n",
    "    #discard non-string categories\n",
    "    def isfloat(value):\n",
    "        try:\n",
    "            float(value)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "    df = df[df['category'].map(lambda x:not isfloat(x))]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "May 20 21:32:05 INFO   Index(['category', 'listing', 'price_btc', 'scrape_date', 'ships_from', 'ships_to', 'vendor'], dtype='object')\n",
      "May 20 21:32:05 INFO   Index(['category', 'listing', 'price_btc', 'scrape_date', 'ships_from', 'ships_to', 'vendor'], dtype='object')\n",
      "INFO:__main__:Index(['category', 'listing', 'price_btc', 'scrape_date', 'ships_from', 'ships_to', 'vendor'], dtype='object')\n",
      "May 20 21:32:05 INFO   (663912, 7)\n",
      "May 20 21:32:05 INFO   (663912, 7)\n",
      "INFO:__main__:(663912, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "drugs           541071\n",
       "digital          20048\n",
       "books            17697\n",
       "apparel          15615\n",
       "drug             15433\n",
       "money            12064\n",
       "custom            9945\n",
       "services          7971\n",
       "forgeries         7086\n",
       "erotica           4177\n",
       "jewelry           2830\n",
       "electronics       2096\n",
       "packaging         1636\n",
       "computer          1273\n",
       "writing           1192\n",
       "lotteries          956\n",
       "hardware           763\n",
       "lab                692\n",
       "medical            538\n",
       "art                531\n",
       "herbs              133\n",
       "biotic              83\n",
       "collectibles        82\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_silkroad2():\n",
    "    DATA_DIR='/home/aahu/Dropbox/black-market-recommender-systems/data/silkroad2/'\n",
    "    l=[]\n",
    "    for fname in os.listdir(DATA_DIR):\n",
    "        if fname.endswith('.tsv'):\n",
    "            try:\n",
    "                df0 = pd.read_csv(os.path.join(DATA_DIR,fname), sep='\\t', parse_dates=['scrape_date'])\n",
    "                l.append(df0)\n",
    "            except ValueError:\n",
    "                logger.exception('no data')\n",
    "                pass\n",
    "    df = pd.concat(l)\n",
    "    logger.info(df.columns)\n",
    "    logger.info(df.shape)\n",
    "    \n",
    "    #be consistent\n",
    "    df['cat'] = df['category'].map(lambda x: x.split('-'))\n",
    "    df['category'] = df['cat'].map(lambda x: x[-1])\n",
    "    \n",
    "    return df\n",
    "\n",
    "sr = load_silkroad2()\n",
    "sr['cat'].map(lambda x:x[0]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "May 20 21:32:10 INFO   Index(['category', 'listing', 'price_btc', 'scrape_date', 'ships_from', 'ships_to', 'vendor'], dtype='object')\n",
      "May 20 21:32:10 INFO   Index(['category', 'listing', 'price_btc', 'scrape_date', 'ships_from', 'ships_to', 'vendor'], dtype='object')\n",
      "INFO:__main__:Index(['category', 'listing', 'price_btc', 'scrape_date', 'ships_from', 'ships_to', 'vendor'], dtype='object')\n",
      "May 20 21:32:10 INFO   (663912, 7)\n",
      "May 20 21:32:10 INFO   (663912, 7)\n",
      "INFO:__main__:(663912, 7)\n",
      "May 20 21:32:12 INFO   (616980, 8)\n",
      "May 20 21:32:12 INFO   (616980, 8)\n",
      "INFO:__main__:(616980, 8)\n"
     ]
    }
   ],
   "source": [
    "# cn = load_cloudnine()\n",
    "# cn = postprocess(cn)\n",
    "# cn.to_csv('/home/aahu/Dropbox/black-market-recommender-systems/data/cloudnine.tsv',sep='\\t',index=False)\n",
    "\n",
    "# ag = load_agora()\n",
    "# ag = postprocess(ag)\n",
    "# ag.to_csv('/home/aahu/Dropbox/black-market-recommender-systems/data/agora.tsv',sep='\\t',index=False)\n",
    "\n",
    "#pa = load_pandora()\n",
    "#pa = postprocess(pa)\n",
    "#pa.to_csv('/home/aahu/Dropbox/black-market-recommender-systems/data/pandora.tsv',sep='\\t',index=False)\n",
    "\n",
    "#hy = load_hydra()\n",
    "#hy = postprocess(hy)\n",
    "#hy.to_csv('/home/aahu/Dropbox/black-market-recommender-systems/data/hydra.tsv',sep='\\t',index=False)\n",
    "\n",
    "# ev = load_evolution()\n",
    "# ev = postprocess(ev)\n",
    "# ev.to_csv('/home/aahu/Dropbox/black-market-recommender-systems/data/evolution.tsv',sep='\\t',index=False)\n",
    "\n",
    "sr2 = load_silkroad2()\n",
    "sr2 = postprocess(sr2)\n",
    "sr2.to_csv('/home/aahu/Dropbox/black-market-recommender-systems/data/silkroad2.tsv',sep='\\t',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ev' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-b2b3f4172c5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mev\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ev' is not defined"
     ]
    }
   ],
   "source": [
    "ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ev['vendor'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
